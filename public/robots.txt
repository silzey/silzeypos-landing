# See https://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file
#
# This file is used to tell web crawlers which pages they can and cannot crawl.

User-agent: *
Allow: /
Disallow: /admin/
Disallow: /dashboard/

Sitemap: https://www.silzeypos.com/sitemap.xml
